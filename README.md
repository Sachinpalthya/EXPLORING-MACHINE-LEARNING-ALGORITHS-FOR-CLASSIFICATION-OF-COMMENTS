# EXPLORING-MACHINE-LEARNING-ALGORITHS-FOR-CLASSIFICATION-OF-COMMENTS
EXPLORING MACHINE LEARNING ALGORITHMS FOR  CLASSIFICATION OF ONLINE TOXIC COMMENTS

PROJECT DESCRIPTION: Toxic comments are disrespectful, abusive, or unreasonable online comments that usually 
make other users leave a discussion. The danger of online bullying and harassment affects the 
free flow of thoughts by restricting the dissenting opinions of people. Sites struggle to promote 
discussions effectively, leading many communities to limit or close down user comments 
altogether. This paper will systematically examine the extent of online harassment and classify 
the content into labels to examine the toxicity as correctly as possible. Here, we will use six 
machine learning algorithms and apply them to our data to solve the problem of text 
classification and to identify the best machine learning algorithm based on our evaluation 
metrics for toxic comments classification. We will aim at examining the toxicity with high 
accuracy to limit down its adverse effects which will be an incentive for organizations to take 
the necessary steps. Online toxic comments refer to any form of harmful, offensive, or abusive 
language expressed in digital platforms such as social media, forums, or comment sections.  
These comments can have significant negative effects on individuals, communities, and 
society as a whole. Some of the key impacts of online toxic comments include: Psychological 
Effects, Cyberbullying, Harm to Communities, Impact on Free Expression, Social Division.  
Addressing online toxic comments requires a multi-faceted approach involving 
technological solutions, community moderation, education on digital citizenship, and legal 
measures to hold perpetrators accountable. Promoting empathy, respect, and civility in online 
interactions is essential to creating a safer and more inclusive digital environment for all users

